Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: sporwal1818 (shri_krishna) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in ./wandb/run-20250331_063113-lyt29uzr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run MAE_ViT_pretraining
wandb: â­ï¸ View project at https://wandb.ai/shri_krishna/DeepLense_FoundationModels_Analysis
wandb: ðŸš€ View run at https://wandb.ai/shri_krishna/DeepLense_FoundationModels_Analysis/runs/lyt29uzr
/home/s_porwal_me.iitr/miniconda3/envs/deeplense/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory results/MAE/MAE_ViT_pretraining/ckpts exists and is not empty.
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
76 4 76 4
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                             â”ƒ Type        â”ƒ Params â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ model                            â”‚ MAE         â”‚  9.1 M â”‚
â”‚ 1  â”‚ model.encoder                    â”‚ ViT         â”‚  8.0 M â”‚
â”‚ 2  â”‚ model.encoder.to_patch_embedding â”‚ Sequential  â”‚  4.9 K â”‚
â”‚ 3  â”‚ model.encoder.transformer        â”‚ Transformer â”‚  7.9 M â”‚
â”‚ 4  â”‚ model.encoder.to_latent          â”‚ Identity    â”‚      0 â”‚
â”‚ 5  â”‚ model.encoder.mlp_head           â”‚ Linear      â”‚    771 â”‚
â”‚ 6  â”‚ model.encoder.dropout            â”‚ Dropout     â”‚      0 â”‚
â”‚ 7  â”‚ model.patch_to_emb               â”‚ Sequential  â”‚  4.9 K â”‚
â”‚ 8  â”‚ model.enc_to_dec                 â”‚ Identity    â”‚      0 â”‚
â”‚ 9  â”‚ model.decoder                    â”‚ Transformer â”‚  1.1 M â”‚
â”‚ 10 â”‚ model.decoder.norm               â”‚ LayerNorm   â”‚    512 â”‚
â”‚ 11 â”‚ model.decoder.layers             â”‚ ModuleList  â”‚  1.1 M â”‚
â”‚ 12 â”‚ model.decoder_pos_emb            â”‚ Embedding   â”‚ 92.7 K â”‚
â”‚ 13 â”‚ model.to_pixels                  â”‚ Linear      â”‚  4.1 K â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 9.1 M                                                         
Non-trainable params: 0                                                         
Total params: 9.1 M                                                             
Total estimated model params size (MB): 36                                      
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
76 4 76 4
[rank: 1] Metric val_MSE_loss improved. New best score: 2.552
[rank: 0] Metric val_MSE_loss improved. New best score: 2.552
Epoch 0, global step 63: 'val_MSE_loss' reached 2.55225 (best 2.55225), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=0 | val_MSE_loss=2.552.ckpt' as top 1
[rank: 1] Metric val_MSE_loss improved by 0.341 >= min_delta = 5e-05. New best score: 2.211
[rank: 0] Metric val_MSE_loss improved by 0.341 >= min_delta = 5e-05. New best score: 2.211
Epoch 1, global step 126: 'val_MSE_loss' reached 2.21141 (best 2.21141), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=1 | val_MSE_loss=2.211.ckpt' as top 1
