Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: sporwal1818 (shri_krishna) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in ./wandb/run-20250331_063113-lyt29uzr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run MAE_ViT_pretraining
wandb: ⭐️ View project at https://wandb.ai/shri_krishna/DeepLense_FoundationModels_Analysis
wandb: 🚀 View run at https://wandb.ai/shri_krishna/DeepLense_FoundationModels_Analysis/runs/lyt29uzr
/home/s_porwal_me.iitr/miniconda3/envs/deeplense/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory results/MAE/MAE_ViT_pretraining/ckpts exists and is not empty.
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
76 4 76 4
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                             ┃ Type        ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ model                            │ MAE         │  9.1 M │
│ 1  │ model.encoder                    │ ViT         │  8.0 M │
│ 2  │ model.encoder.to_patch_embedding │ Sequential  │  4.9 K │
│ 3  │ model.encoder.transformer        │ Transformer │  7.9 M │
│ 4  │ model.encoder.to_latent          │ Identity    │      0 │
│ 5  │ model.encoder.mlp_head           │ Linear      │    771 │
│ 6  │ model.encoder.dropout            │ Dropout     │      0 │
│ 7  │ model.patch_to_emb               │ Sequential  │  4.9 K │
│ 8  │ model.enc_to_dec                 │ Identity    │      0 │
│ 9  │ model.decoder                    │ Transformer │  1.1 M │
│ 10 │ model.decoder.norm               │ LayerNorm   │    512 │
│ 11 │ model.decoder.layers             │ ModuleList  │  1.1 M │
│ 12 │ model.decoder_pos_emb            │ Embedding   │ 92.7 K │
│ 13 │ model.to_pixels                  │ Linear      │  4.1 K │
└────┴──────────────────────────────────┴─────────────┴────────┘
Trainable params: 9.1 M                                                         
Non-trainable params: 0                                                         
Total params: 9.1 M                                                             
Total estimated model params size (MB): 36                                      
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
76 4 76 4
[rank: 1] Metric val_MSE_loss improved. New best score: 2.552
[rank: 0] Metric val_MSE_loss improved. New best score: 2.552
Epoch 0, global step 63: 'val_MSE_loss' reached 2.55225 (best 2.55225), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=0 | val_MSE_loss=2.552.ckpt' as top 1
[rank: 1] Metric val_MSE_loss improved by 0.341 >= min_delta = 5e-05. New best score: 2.211
[rank: 0] Metric val_MSE_loss improved by 0.341 >= min_delta = 5e-05. New best score: 2.211
Epoch 1, global step 126: 'val_MSE_loss' reached 2.21141 (best 2.21141), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=1 | val_MSE_loss=2.211.ckpt' as top 1
[rank: 0] Metric val_MSE_loss improved by 0.518 >= min_delta = 5e-05. New best score: 1.694
[rank: 1] Metric val_MSE_loss improved by 0.518 >= min_delta = 5e-05. New best score: 1.694
Epoch 2, global step 189: 'val_MSE_loss' reached 1.69389 (best 1.69389), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=2 | val_MSE_loss=1.694.ckpt' as top 1
[rank: 0] Metric val_MSE_loss improved by 0.079 >= min_delta = 5e-05. New best score: 1.615
[rank: 1] Metric val_MSE_loss improved by 0.079 >= min_delta = 5e-05. New best score: 1.615
Epoch 3, global step 252: 'val_MSE_loss' reached 1.61482 (best 1.61482), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=3 | val_MSE_loss=1.615.ckpt' as top 1
[rank: 0] Metric val_MSE_loss improved by 0.025 >= min_delta = 5e-05. New best score: 1.590
[rank: 1] Metric val_MSE_loss improved by 0.025 >= min_delta = 5e-05. New best score: 1.590
Epoch 4, global step 315: 'val_MSE_loss' reached 1.58967 (best 1.58967), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=4 | val_MSE_loss=1.590.ckpt' as top 1
[rank: 1] Metric val_MSE_loss improved by 0.022 >= min_delta = 5e-05. New best score: 1.567
[rank: 0] Metric val_MSE_loss improved by 0.022 >= min_delta = 5e-05. New best score: 1.567
Epoch 5, global step 378: 'val_MSE_loss' reached 1.56741 (best 1.56741), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=5 | val_MSE_loss=1.567.ckpt' as top 1
[rank: 1] Metric val_MSE_loss improved by 0.018 >= min_delta = 5e-05. New best score: 1.549
[rank: 0] Metric val_MSE_loss improved by 0.018 >= min_delta = 5e-05. New best score: 1.549
Epoch 6, global step 441: 'val_MSE_loss' reached 1.54899 (best 1.54899), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=6 | val_MSE_loss=1.549.ckpt' as top 1
[rank: 0] Metric val_MSE_loss improved by 0.194 >= min_delta = 5e-05. New best score: 1.355
[rank: 1] Metric val_MSE_loss improved by 0.194 >= min_delta = 5e-05. New best score: 1.355
Epoch 7, global step 504: 'val_MSE_loss' reached 1.35505 (best 1.35505), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=7 | val_MSE_loss=1.355.ckpt' as top 1
[rank: 0] Metric val_MSE_loss improved by 0.666 >= min_delta = 5e-05. New best score: 0.689
[rank: 1] Metric val_MSE_loss improved by 0.666 >= min_delta = 5e-05. New best score: 0.689
Epoch 8, global step 567: 'val_MSE_loss' reached 0.68859 (best 0.68859), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=8 | val_MSE_loss=0.689.ckpt' as top 1
[rank: 0] Metric val_MSE_loss improved by 0.240 >= min_delta = 5e-05. New best score: 0.448
[rank: 1] Metric val_MSE_loss improved by 0.240 >= min_delta = 5e-05. New best score: 0.448
Epoch 9, global step 630: 'val_MSE_loss' reached 0.44816 (best 0.44816), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=9 | val_MSE_loss=0.448.ckpt' as top 1
[rank: 1] Metric val_MSE_loss improved by 0.154 >= min_delta = 5e-05. New best score: 0.294
[rank: 0] Metric val_MSE_loss improved by 0.154 >= min_delta = 5e-05. New best score: 0.294
Epoch 10, global step 693: 'val_MSE_loss' reached 0.29440 (best 0.29440), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=10 | val_MSE_loss=0.294.ckpt' as top 1
[rank: 1] Metric val_MSE_loss improved by 0.049 >= min_delta = 5e-05. New best score: 0.246
[rank: 0] Metric val_MSE_loss improved by 0.049 >= min_delta = 5e-05. New best score: 0.246
Epoch 11, global step 756: 'val_MSE_loss' reached 0.24590 (best 0.24590), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=11 | val_MSE_loss=0.246.ckpt' as top 1
[rank: 0] Metric val_MSE_loss improved by 0.032 >= min_delta = 5e-05. New best score: 0.214
[rank: 1] Metric val_MSE_loss improved by 0.032 >= min_delta = 5e-05. New best score: 0.214
Epoch 12, global step 819: 'val_MSE_loss' reached 0.21400 (best 0.21400), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=12 | val_MSE_loss=0.214.ckpt' as top 1
[rank: 0] Metric val_MSE_loss improved by 0.022 >= min_delta = 5e-05. New best score: 0.192
[rank: 1] Metric val_MSE_loss improved by 0.022 >= min_delta = 5e-05. New best score: 0.192
Epoch 13, global step 882: 'val_MSE_loss' reached 0.19209 (best 0.19209), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=13 | val_MSE_loss=0.192.ckpt' as top 1
[rank: 1] Metric val_MSE_loss improved by 0.012 >= min_delta = 5e-05. New best score: 0.180
[rank: 0] Metric val_MSE_loss improved by 0.012 >= min_delta = 5e-05. New best score: 0.180
Epoch 14, global step 945: 'val_MSE_loss' reached 0.17976 (best 0.17976), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=14 | val_MSE_loss=0.180.ckpt' as top 1
Epoch 15, global step 1008: 'val_MSE_loss' was not in top 1
[rank: 0] Metric val_MSE_loss improved by 0.015 >= min_delta = 5e-05. New best score: 0.165
[rank: 1] Metric val_MSE_loss improved by 0.015 >= min_delta = 5e-05. New best score: 0.165
Epoch 16, global step 1071: 'val_MSE_loss' reached 0.16469 (best 0.16469), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=16 | val_MSE_loss=0.165.ckpt' as top 1
[rank: 0] Metric val_MSE_loss improved by 0.014 >= min_delta = 5e-05. New best score: 0.150
[rank: 1] Metric val_MSE_loss improved by 0.014 >= min_delta = 5e-05. New best score: 0.150
Epoch 17, global step 1134: 'val_MSE_loss' reached 0.15028 (best 0.15028), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=17 | val_MSE_loss=0.150.ckpt' as top 1
[rank: 0] Metric val_MSE_loss improved by 0.008 >= min_delta = 5e-05. New best score: 0.142
[rank: 1] Metric val_MSE_loss improved by 0.008 >= min_delta = 5e-05. New best score: 0.142
Epoch 18, global step 1197: 'val_MSE_loss' reached 0.14211 (best 0.14211), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=18 | val_MSE_loss=0.142.ckpt' as top 1
[rank: 1] Metric val_MSE_loss improved by 0.004 >= min_delta = 5e-05. New best score: 0.139
[rank: 0] Metric val_MSE_loss improved by 0.004 >= min_delta = 5e-05. New best score: 0.139
Epoch 19, global step 1260: 'val_MSE_loss' reached 0.13853 (best 0.13853), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=19 | val_MSE_loss=0.139.ckpt' as top 1
[rank: 1] Metric val_MSE_loss improved by 0.015 >= min_delta = 5e-05. New best score: 0.123
[rank: 0] Metric val_MSE_loss improved by 0.015 >= min_delta = 5e-05. New best score: 0.123
Epoch 20, global step 1323: 'val_MSE_loss' reached 0.12310 (best 0.12310), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=20 | val_MSE_loss=0.123.ckpt' as top 1
[rank: 1] Metric val_MSE_loss improved by 0.003 >= min_delta = 5e-05. New best score: 0.121
[rank: 0] Metric val_MSE_loss improved by 0.003 >= min_delta = 5e-05. New best score: 0.121
Epoch 21, global step 1386: 'val_MSE_loss' reached 0.12056 (best 0.12056), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=21 | val_MSE_loss=0.121.ckpt' as top 1
Epoch 22, global step 1449: 'val_MSE_loss' was not in top 1
[rank: 0] Metric val_MSE_loss improved by 0.015 >= min_delta = 5e-05. New best score: 0.106
[rank: 1] Metric val_MSE_loss improved by 0.015 >= min_delta = 5e-05. New best score: 0.106
Epoch 23, global step 1512: 'val_MSE_loss' reached 0.10586 (best 0.10586), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=23 | val_MSE_loss=0.106.ckpt' as top 1
Epoch 24, global step 1575: 'val_MSE_loss' was not in top 1
[rank: 0] Metric val_MSE_loss improved by 0.003 >= min_delta = 5e-05. New best score: 0.103
[rank: 1] Metric val_MSE_loss improved by 0.003 >= min_delta = 5e-05. New best score: 0.103
Epoch 25, global step 1638: 'val_MSE_loss' reached 0.10289 (best 0.10289), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=25 | val_MSE_loss=0.103.ckpt' as top 1
[rank: 1] Metric val_MSE_loss improved by 0.007 >= min_delta = 5e-05. New best score: 0.096
[rank: 0] Metric val_MSE_loss improved by 0.007 >= min_delta = 5e-05. New best score: 0.096
Epoch 26, global step 1701: 'val_MSE_loss' reached 0.09553 (best 0.09553), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=26 | val_MSE_loss=0.096.ckpt' as top 1
Epoch 27, global step 1764: 'val_MSE_loss' was not in top 1
Epoch 28, global step 1827: 'val_MSE_loss' was not in top 1
[rank: 0] Metric val_MSE_loss improved by 0.013 >= min_delta = 5e-05. New best score: 0.083
[rank: 1] Metric val_MSE_loss improved by 0.013 >= min_delta = 5e-05. New best score: 0.083
Epoch 29, global step 1890: 'val_MSE_loss' reached 0.08255 (best 0.08255), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=29 | val_MSE_loss=0.083.ckpt' as top 1
Epoch 30, global step 1953: 'val_MSE_loss' was not in top 1
Epoch 31, global step 2016: 'val_MSE_loss' was not in top 1
[rank: 0] Metric val_MSE_loss improved by 0.004 >= min_delta = 5e-05. New best score: 0.079
[rank: 1] Metric val_MSE_loss improved by 0.004 >= min_delta = 5e-05. New best score: 0.079
Epoch 32, global step 2079: 'val_MSE_loss' reached 0.07851 (best 0.07851), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=32 | val_MSE_loss=0.079.ckpt' as top 1
Epoch 33, global step 2142: 'val_MSE_loss' was not in top 1
[rank: 0] Metric val_MSE_loss improved by 0.001 >= min_delta = 5e-05. New best score: 0.077
[rank: 1] Metric val_MSE_loss improved by 0.001 >= min_delta = 5e-05. New best score: 0.077
Epoch 34, global step 2205: 'val_MSE_loss' reached 0.07701 (best 0.07701), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=34 | val_MSE_loss=0.077.ckpt' as top 1
[rank: 0] Metric val_MSE_loss improved by 0.008 >= min_delta = 5e-05. New best score: 0.069
[rank: 1] Metric val_MSE_loss improved by 0.008 >= min_delta = 5e-05. New best score: 0.069
Epoch 35, global step 2268: 'val_MSE_loss' reached 0.06920 (best 0.06920), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=35 | val_MSE_loss=0.069.ckpt' as top 1
Epoch 36, global step 2331: 'val_MSE_loss' was not in top 1
Epoch 37, global step 2394: 'val_MSE_loss' was not in top 1
Epoch 38, global step 2457: 'val_MSE_loss' was not in top 1
Epoch 39, global step 2520: 'val_MSE_loss' was not in top 1
[rank: 1] Metric val_MSE_loss improved by 0.004 >= min_delta = 5e-05. New best score: 0.065
[rank: 0] Metric val_MSE_loss improved by 0.004 >= min_delta = 5e-05. New best score: 0.065
Epoch 40, global step 2583: 'val_MSE_loss' reached 0.06472 (best 0.06472), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=40 | val_MSE_loss=0.065.ckpt' as top 1
[rank: 1] Metric val_MSE_loss improved by 0.002 >= min_delta = 5e-05. New best score: 0.063
[rank: 0] Metric val_MSE_loss improved by 0.002 >= min_delta = 5e-05. New best score: 0.063
Epoch 41, global step 2646: 'val_MSE_loss' reached 0.06263 (best 0.06263), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=41 | val_MSE_loss=0.063.ckpt' as top 1
Epoch 42, global step 2709: 'val_MSE_loss' was not in top 1
[rank: 0] Metric val_MSE_loss improved by 0.003 >= min_delta = 5e-05. New best score: 0.060
[rank: 1] Metric val_MSE_loss improved by 0.003 >= min_delta = 5e-05. New best score: 0.060
Epoch 43, global step 2772: 'val_MSE_loss' reached 0.06004 (best 0.06004), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=43 | val_MSE_loss=0.060.ckpt' as top 1
Epoch 44, global step 2835: 'val_MSE_loss' was not in top 1
[rank: 0] Metric val_MSE_loss improved by 0.005 >= min_delta = 5e-05. New best score: 0.055
[rank: 1] Metric val_MSE_loss improved by 0.005 >= min_delta = 5e-05. New best score: 0.055
Epoch 45, global step 2898: 'val_MSE_loss' reached 0.05523 (best 0.05523), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=45 | val_MSE_loss=0.055.ckpt' as top 1
Epoch 46, global step 2961: 'val_MSE_loss' was not in top 1
Epoch 47, global step 3024: 'val_MSE_loss' was not in top 1
Epoch 48, global step 3087: 'val_MSE_loss' was not in top 1
Epoch 49, global step 3150: 'val_MSE_loss' was not in top 1
Epoch 50, global step 3213: 'val_MSE_loss' was not in top 1
Epoch 51, global step 3276: 'val_MSE_loss' was not in top 1
[rank: 1] Metric val_MSE_loss improved by 0.001 >= min_delta = 5e-05. New best score: 0.054
[rank: 0] Metric val_MSE_loss improved by 0.001 >= min_delta = 5e-05. New best score: 0.054
Epoch 52, global step 3339: 'val_MSE_loss' reached 0.05382 (best 0.05382), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=52 | val_MSE_loss=0.054.ckpt' as top 1
Epoch 53, global step 3402: 'val_MSE_loss' was not in top 1
Epoch 54, global step 3465: 'val_MSE_loss' was not in top 1
Epoch 55, global step 3528: 'val_MSE_loss' was not in top 1
[rank: 0] Metric val_MSE_loss improved by 0.001 >= min_delta = 5e-05. New best score: 0.053
[rank: 1] Metric val_MSE_loss improved by 0.001 >= min_delta = 5e-05. New best score: 0.053
Epoch 56, global step 3591: 'val_MSE_loss' reached 0.05316 (best 0.05316), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=56 | val_MSE_loss=0.053.ckpt' as top 1
[rank: 0] Metric val_MSE_loss improved by 0.008 >= min_delta = 5e-05. New best score: 0.045
[rank: 1] Metric val_MSE_loss improved by 0.008 >= min_delta = 5e-05. New best score: 0.045
Epoch 57, global step 3654: 'val_MSE_loss' reached 0.04506 (best 0.04506), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=57 | val_MSE_loss=0.045.ckpt' as top 1
[rank: 0] Metric val_MSE_loss improved by 0.001 >= min_delta = 5e-05. New best score: 0.044
[rank: 1] Metric val_MSE_loss improved by 0.001 >= min_delta = 5e-05. New best score: 0.044
Epoch 58, global step 3717: 'val_MSE_loss' reached 0.04416 (best 0.04416), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=58 | val_MSE_loss=0.044.ckpt' as top 1
[rank: 0] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.044
[rank: 1] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.044
Epoch 59, global step 3780: 'val_MSE_loss' reached 0.04394 (best 0.04394), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=59 | val_MSE_loss=0.044.ckpt' as top 1
Epoch 60, global step 3843: 'val_MSE_loss' was not in top 1
Epoch 61, global step 3906: 'val_MSE_loss' was not in top 1
Epoch 62, global step 3969: 'val_MSE_loss' was not in top 1
Epoch 63, global step 4032: 'val_MSE_loss' was not in top 1
[rank: 0] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.044
[rank: 1] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.044
Epoch 64, global step 4095: 'val_MSE_loss' reached 0.04362 (best 0.04362), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=64 | val_MSE_loss=0.044.ckpt' as top 1
[rank: 1] Metric val_MSE_loss improved by 0.003 >= min_delta = 5e-05. New best score: 0.040
[rank: 0] Metric val_MSE_loss improved by 0.003 >= min_delta = 5e-05. New best score: 0.040
Epoch 65, global step 4158: 'val_MSE_loss' reached 0.04017 (best 0.04017), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=65 | val_MSE_loss=0.040.ckpt' as top 1
Epoch 66, global step 4221: 'val_MSE_loss' reached 0.04016 (best 0.04016), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=66 | val_MSE_loss=0.040.ckpt' as top 1
Epoch 67, global step 4284: 'val_MSE_loss' was not in top 1
Epoch 68, global step 4347: 'val_MSE_loss' was not in top 1
Epoch 69, global step 4410: 'val_MSE_loss' was not in top 1
[rank: 0] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.040
[rank: 1] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.040
Epoch 70, global step 4473: 'val_MSE_loss' reached 0.03968 (best 0.03968), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=70 | val_MSE_loss=0.040.ckpt' as top 1
Epoch 71, global step 4536: 'val_MSE_loss' was not in top 1
Epoch 72, global step 4599: 'val_MSE_loss' was not in top 1
Epoch 73, global step 4662: 'val_MSE_loss' was not in top 1
[rank: 1] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.040
[rank: 0] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.040
Epoch 74, global step 4725: 'val_MSE_loss' reached 0.03958 (best 0.03958), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=74 | val_MSE_loss=0.040.ckpt' as top 1
Epoch 75, global step 4788: 'val_MSE_loss' was not in top 1
Epoch 76, global step 4851: 'val_MSE_loss' was not in top 1
Epoch 77, global step 4914: 'val_MSE_loss' was not in top 1
Epoch 78, global step 4977: 'val_MSE_loss' was not in top 1
[rank: 0] Metric val_MSE_loss improved by 0.003 >= min_delta = 5e-05. New best score: 0.036
[rank: 1] Metric val_MSE_loss improved by 0.003 >= min_delta = 5e-05. New best score: 0.036
Epoch 79, global step 5040: 'val_MSE_loss' reached 0.03613 (best 0.03613), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=79 | val_MSE_loss=0.036.ckpt' as top 1
Epoch 80, global step 5103: 'val_MSE_loss' was not in top 1
Epoch 81, global step 5166: 'val_MSE_loss' was not in top 1
Epoch 82, global step 5229: 'val_MSE_loss' was not in top 1
Epoch 83, global step 5292: 'val_MSE_loss' was not in top 1
[rank: 0] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.036
[rank: 1] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.036
Epoch 84, global step 5355: 'val_MSE_loss' reached 0.03590 (best 0.03590), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=84 | val_MSE_loss=0.036.ckpt' as top 1
Epoch 85, global step 5418: 'val_MSE_loss' was not in top 1
Epoch 86, global step 5481: 'val_MSE_loss' was not in top 1
Epoch 87, global step 5544: 'val_MSE_loss' was not in top 1
Epoch 88, global step 5607: 'val_MSE_loss' was not in top 1
Epoch 89, global step 5670: 'val_MSE_loss' was not in top 1
Epoch 90, global step 5733: 'val_MSE_loss' was not in top 1
[rank: 0] Metric val_MSE_loss improved by 0.003 >= min_delta = 5e-05. New best score: 0.033
[rank: 1] Metric val_MSE_loss improved by 0.003 >= min_delta = 5e-05. New best score: 0.033
Epoch 91, global step 5796: 'val_MSE_loss' reached 0.03273 (best 0.03273), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=91 | val_MSE_loss=0.033.ckpt' as top 1
Epoch 92, global step 5859: 'val_MSE_loss' was not in top 1
Epoch 93, global step 5922: 'val_MSE_loss' was not in top 1
[rank: 1] Metric val_MSE_loss improved by 0.004 >= min_delta = 5e-05. New best score: 0.028
[rank: 0] Metric val_MSE_loss improved by 0.004 >= min_delta = 5e-05. New best score: 0.028
Epoch 94, global step 5985: 'val_MSE_loss' reached 0.02840 (best 0.02840), saving model to 'results/MAE/MAE_ViT_pretraining/ckpts/epoch=94 | val_MSE_loss=0.028.ckpt' as top 1
Epoch 95, global step 6048: 'val_MSE_loss' was not in top 1
Epoch 96, global step 6111: 'val_MSE_loss' was not in top 1
Epoch 97, global step 6174: 'val_MSE_loss' was not in top 1
Epoch 98, global step 6237: 'val_MSE_loss' was not in top 1
Epoch 99, global step 6300: 'val_MSE_loss' was not in top 1
Epoch 100, global step 6363: 'val_MSE_loss' was not in top 1
Epoch 101, global step 6426: 'val_MSE_loss' was not in top 1
[rank: 0] Monitored metric val_MSE_loss did not improve in the last 8 records. Best score: 0.028. Signaling Trainer to stop.
[rank: 1] Monitored metric val_MSE_loss did not improve in the last 8 records. Best score: 0.028. Signaling Trainer to stop.
Epoch 102, global step 6489: 'val_MSE_loss' was not in top 1
Epoch 102/149 ━━━━━━━━━━━━━━━ 187/187 0:00:17 •       10.88it/s v_num: r_12     
                                      0:00:00                   val_MSE_loss:   
                                                                0.032           
                                                                train_MSE_loss: 
                                                                0.097           
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
/home/s_porwal_me.iitr/miniconda3/envs/deeplense/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:232: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│       test_MSE_loss       │    0.03330673649907112    │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24/24 0:00:01 • 0:00:00 13.57it/s 
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mMAE_ViT_pretraining[0m at: [34mhttps://wandb.ai/shri_krishna/DeepLense_FoundationModels_Analysis/runs/lyt29uzr[0m
