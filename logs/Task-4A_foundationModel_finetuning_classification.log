Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: sporwal1818 (shri_krishna) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in ./wandb/run-20250326_224437-kje6vyxn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Task-4A_ViT_finetuned_classification
wandb: ⭐️ View project at https://wandb.ai/shri_krishna/DeepLense_FoundationModels_Analysis
wandb: 🚀 View run at https://wandb.ai/shri_krishna/DeepLense_FoundationModels_Analysis/runs/kje6vyxn
/home/s_porwal_me.iitr/miniconda3/envs/deeplense/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory results/MAE/Task-4A_ViT_finetuned_classification/ckpts exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
64 4 64 4
Successfully loaded the model weights for classification
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃    ┃ Name                       ┃ Type                 ┃ Params ┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│ 0  │ model                      │ ViT                  │  959 K │
│ 1  │ model.to_patch_embedding   │ Sequential           │  2.5 K │
│ 2  │ model.to_patch_embedding.0 │ Rearrange            │      0 │
│ 3  │ model.to_patch_embedding.1 │ LayerNorm            │     32 │
│ 4  │ model.to_patch_embedding.2 │ Linear               │  2.2 K │
│ 5  │ model.to_patch_embedding.3 │ LayerNorm            │    256 │
│ 6  │ model.transformer          │ Transformer          │  923 K │
│ 7  │ model.transformer.norm     │ LayerNorm            │    256 │
│ 8  │ model.transformer.layers   │ ModuleList           │  923 K │
│ 9  │ model.to_latent            │ Identity             │      0 │
│ 10 │ model.mlp_head             │ Linear               │    387 │
│ 11 │ model.dropout              │ Dropout              │      0 │
│ 12 │ tr_kappa                   │ MulticlassCohenKappa │      0 │
│ 13 │ val_kappa                  │ MulticlassCohenKappa │      0 │
│ 14 │ tst_kappa                  │ MulticlassCohenKappa │      0 │
│ 15 │ tr_accuracy                │ MulticlassAccuracy   │      0 │
│ 16 │ val_accuracy               │ MulticlassAccuracy   │      0 │
│ 17 │ tst_accuracy               │ MulticlassAccuracy   │      0 │
│ 18 │ criterion                  │ CrossEntropyLoss     │      0 │
└────┴────────────────────────────┴──────────────────────┴────────┘
Trainable params: 959 K                                                         
Non-trainable params: 0                                                         
Total params: 959 K                                                             
Total estimated model params size (MB): 3                                       
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
64 4 64 4
Successfully loaded the model weights for classification
[rank: 0] Metric val_ce_loss improved. New best score: 1.099
[rank: 1] Metric val_ce_loss improved. New best score: 1.099
Epoch 0, global step 188: 'val_ce_loss' reached 1.09861 (best 1.09861), saving model to 'results/MAE/Task-4A_ViT_finetuned_classification/ckpts/epoch=0 | val_ce_loss=1.099.ckpt' as top 1
Epoch 1, global step 376: 'val_ce_loss' was not in top 1
Epoch 2, global step 564: 'val_ce_loss' was not in top 1
[rank: 0] Metric val_ce_loss improved by 0.000 >= min_delta = 5e-05. New best score: 1.098
[rank: 1] Metric val_ce_loss improved by 0.000 >= min_delta = 5e-05. New best score: 1.098
Epoch 3, global step 752: 'val_ce_loss' reached 1.09846 (best 1.09846), saving model to 'results/MAE/Task-4A_ViT_finetuned_classification/ckpts/epoch=3 | val_ce_loss=1.098.ckpt' as top 1
Epoch 4, global step 940: 'val_ce_loss' was not in top 1
[rank: 0] Metric val_ce_loss improved by 0.000 >= min_delta = 5e-05. New best score: 1.098
[rank: 1] Metric val_ce_loss improved by 0.000 >= min_delta = 5e-05. New best score: 1.098
Epoch 5, global step 1128: 'val_ce_loss' reached 1.09816 (best 1.09816), saving model to 'results/MAE/Task-4A_ViT_finetuned_classification/ckpts/epoch=5 | val_ce_loss=1.098.ckpt' as top 1
[rank: 0] Metric val_ce_loss improved by 0.001 >= min_delta = 5e-05. New best score: 1.098
[rank: 1] Metric val_ce_loss improved by 0.001 >= min_delta = 5e-05. New best score: 1.098
Epoch 6, global step 1316: 'val_ce_loss' reached 1.09752 (best 1.09752), saving model to 'results/MAE/Task-4A_ViT_finetuned_classification/ckpts/epoch=6 | val_ce_loss=1.098.ckpt' as top 1
[rank: 1] Metric val_ce_loss improved by 0.002 >= min_delta = 5e-05. New best score: 1.096
[rank: 0] Metric val_ce_loss improved by 0.002 >= min_delta = 5e-05. New best score: 1.096
Epoch 7, global step 1504: 'val_ce_loss' reached 1.09565 (best 1.09565), saving model to 'results/MAE/Task-4A_ViT_finetuned_classification/ckpts/epoch=7 | val_ce_loss=1.096.ckpt' as top 1
[rank: 0] Metric val_ce_loss improved by 0.008 >= min_delta = 5e-05. New best score: 1.087
[rank: 1] Metric val_ce_loss improved by 0.008 >= min_delta = 5e-05. New best score: 1.087
Epoch 8, global step 1692: 'val_ce_loss' reached 1.08716 (best 1.08716), saving model to 'results/MAE/Task-4A_ViT_finetuned_classification/ckpts/epoch=8 | val_ce_loss=1.087.ckpt' as top 1
Epoch 9, global step 1880: 'val_ce_loss' was not in top 1
Epoch 10, global step 2068: 'val_ce_loss' was not in top 1
Epoch 11, global step 2256: 'val_ce_loss' was not in top 1
Epoch 12, global step 2444: 'val_ce_loss' was not in top 1
Epoch 13, global step 2632: 'val_ce_loss' was not in top 1
Epoch 14, global step 2820: 'val_ce_loss' was not in top 1
Epoch 15, global step 3008: 'val_ce_loss' was not in top 1
[rank: 0] Monitored metric val_ce_loss did not improve in the last 8 records. Best score: 1.087. Signaling Trainer to stop.
[rank: 1] Monitored metric val_ce_loss did not improve in the last 8 records. Best score: 1.087. Signaling Trainer to stop.
Epoch 16, global step 3196: 'val_ce_loss' was not in top 1
Epoch 16/99 ━━━━━━━━━━━━━━━━ 564/564 0:00:44 •       13.13it/s v_num: xn_0      
                                     0:00:00                   val_ce_loss:     
                                                               1.439 val_kappa: 
                                                               0.057 val_acc:   
                                                               0.357            
                                                               train_ce_loss:   
                                                               1.014            
                                                               train_kappa:     
                                                               0.350 train_acc: 
                                                               0.466            
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
/home/s_porwal_me.iitr/miniconda3/envs/deeplense/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:232: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃        Test metric        ┃       DataLoader 0        ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│      test_acc_epoch       │    0.3550269305706024     │
│    test_ce_loss_epoch     │    1.4427001476287842     │
│     test_kappa_epoch      │   0.054676055908203125    │
└───────────────────────────┴───────────────────────────┘
Testing ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 70/70 0:00:08 • 0:00:00 8.24it/s 
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33mTask-4A_ViT_finetuned_classification[0m at: [34mhttps://wandb.ai/shri_krishna/DeepLense_FoundationModels_Analysis/runs/kje6vyxn[0m
