/home/s_porwal_me.iitr/miniconda3/envs/deeplense/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
/home/s_porwal_me.iitr/miniconda3/envs/deeplense/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `PeakSignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `PeakSignalNoiseRatio` from `torchmetrics.image` instead.
  _future_warning(
Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: sporwal1818 (shri_krishna) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in ./wandb/run-20250331_002057-ibqziwud
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Task-4B_SuperRes_finetuned_super_res
wandb: ‚≠êÔ∏è View project at https://wandb.ai/shri_krishna/DeepLense_FoundationModels_Analysis
wandb: üöÄ View run at https://wandb.ai/shri_krishna/DeepLense_FoundationModels_Analysis/runs/ibqziwud
/home/s_porwal_me.iitr/miniconda3/envs/deeplense/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory results/MAE/Task-4B_SuperRes_finetuned_super_res/ckpts exists and is not empty.
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
76 4 76 4
Successfully loaded the encoder weights for Super Resolution
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ    ‚îÉ Name                                      ‚îÉ Type               ‚îÉ Params ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ 0  ‚îÇ model                                     ‚îÇ SuperResolutionAE  ‚îÇ 13.2 M ‚îÇ
‚îÇ 1  ‚îÇ model.encoder                             ‚îÇ ViT                ‚îÇ  8.0 M ‚îÇ
‚îÇ 2  ‚îÇ model.encoder.to_patch_embedding          ‚îÇ Sequential         ‚îÇ  4.9 K ‚îÇ
‚îÇ 3  ‚îÇ model.encoder.transformer                 ‚îÇ Transformer        ‚îÇ  7.9 M ‚îÇ
‚îÇ 4  ‚îÇ model.encoder.to_latent                   ‚îÇ Identity           ‚îÇ      0 ‚îÇ
‚îÇ 5  ‚îÇ model.encoder.mlp_head                    ‚îÇ Linear             ‚îÇ    771 ‚îÇ
‚îÇ 6  ‚îÇ model.encoder.dropout                     ‚îÇ Dropout            ‚îÇ      0 ‚îÇ
‚îÇ 7  ‚îÇ model.patch_to_emb                        ‚îÇ Sequential         ‚îÇ  4.9 K ‚îÇ
‚îÇ 8  ‚îÇ model.reshape_patches_to_img              ‚îÇ Rearrange          ‚îÇ      0 ‚îÇ
‚îÇ 9  ‚îÇ model.super_res_decoder                   ‚îÇ SuperResolutionDe‚Ä¶ ‚îÇ  5.2 M ‚îÇ
‚îÇ 10 ‚îÇ model.super_res_decoder.initial           ‚îÇ Sequential         ‚îÇ  295 K ‚îÇ
‚îÇ 11 ‚îÇ model.super_res_decoder.residual_blocks   ‚îÇ ModuleList         ‚îÇ  3.0 M ‚îÇ
‚îÇ 12 ‚îÇ model.super_res_decoder.global_res_conv   ‚îÇ Conv2d             ‚îÇ  147 K ‚îÇ
‚îÇ 13 ‚îÇ model.super_res_decoder.upsampling_layers ‚îÇ ModuleList         ‚îÇ  1.8 M ‚îÇ
‚îÇ 14 ‚îÇ model.super_res_decoder.final             ‚îÇ Conv2d             ‚îÇ  1.2 K ‚îÇ
‚îÇ 15 ‚îÇ tr_ssim                                   ‚îÇ StructuralSimilar‚Ä¶ ‚îÇ      0 ‚îÇ
‚îÇ 16 ‚îÇ val_ssim                                  ‚îÇ StructuralSimilar‚Ä¶ ‚îÇ      0 ‚îÇ
‚îÇ 17 ‚îÇ tst_ssim                                  ‚îÇ StructuralSimilar‚Ä¶ ‚îÇ      0 ‚îÇ
‚îÇ 18 ‚îÇ mse                                       ‚îÇ MSELoss            ‚îÇ      0 ‚îÇ
‚îÇ 19 ‚îÇ tr_psnr                                   ‚îÇ _PeakSignalNoiseR‚Ä¶ ‚îÇ      0 ‚îÇ
‚îÇ 20 ‚îÇ val_psnr                                  ‚îÇ _PeakSignalNoiseR‚Ä¶ ‚îÇ      0 ‚îÇ
‚îÇ 21 ‚îÇ tst_psnr                                  ‚îÇ _PeakSignalNoiseR‚Ä¶ ‚îÇ      0 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Trainable params: 13.2 M                                                        
Non-trainable params: 0                                                         
Total params: 13.2 M                                                            
Total estimated model params size (MB): 52                                      
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
76 4 76 4
Successfully loaded the encoder weights for Super Resolution
[rank: 0] Metric val_MSE_loss improved. New best score: 0.005
[rank: 1] Metric val_MSE_loss improved. New best score: 0.005
Epoch 0, global step 22: 'val_MSE_loss' reached 0.00489 (best 0.00489), saving model to 'results/MAE/Task-4B_SuperRes_finetuned_super_res/ckpts/epoch=0 | val_MSE_loss=0.005.ckpt' as top 1
[rank: 0] Metric val_MSE_loss improved by 0.004 >= min_delta = 5e-05. New best score: 0.001
[rank: 1] Metric val_MSE_loss improved by 0.004 >= min_delta = 5e-05. New best score: 0.001
Epoch 1, global step 44: 'val_MSE_loss' reached 0.00063 (best 0.00063), saving model to 'results/MAE/Task-4B_SuperRes_finetuned_super_res/ckpts/epoch=1 | val_MSE_loss=0.001.ckpt' as top 1
[rank: 1] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.000
[rank: 0] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.000
Epoch 2, global step 66: 'val_MSE_loss' reached 0.00042 (best 0.00042), saving model to 'results/MAE/Task-4B_SuperRes_finetuned_super_res/ckpts/epoch=2 | val_MSE_loss=0.000.ckpt' as top 1
[rank: 0] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.000
[rank: 1] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.000
Epoch 3, global step 88: 'val_MSE_loss' reached 0.00037 (best 0.00037), saving model to 'results/MAE/Task-4B_SuperRes_finetuned_super_res/ckpts/epoch=3 | val_MSE_loss=0.000.ckpt' as top 1
Epoch 4, global step 110: 'val_MSE_loss' was not in top 1
Epoch 5, global step 132: 'val_MSE_loss' was not in top 1
[rank: 0] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.000
[rank: 1] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.000
Epoch 6, global step 154: 'val_MSE_loss' reached 0.00026 (best 0.00026), saving model to 'results/MAE/Task-4B_SuperRes_finetuned_super_res/ckpts/epoch=6 | val_MSE_loss=0.000.ckpt' as top 1
Epoch 7, global step 176: 'val_MSE_loss' was not in top 1
Epoch 8, global step 198: 'val_MSE_loss' reached 0.00023 (best 0.00023), saving model to 'results/MAE/Task-4B_SuperRes_finetuned_super_res/ckpts/epoch=8 | val_MSE_loss=0.000.ckpt' as top 1
Epoch 9, global step 220: 'val_MSE_loss' was not in top 1
Epoch 10, global step 242: 'val_MSE_loss' was not in top 1
[rank: 0] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.000
[rank: 1] Metric val_MSE_loss improved by 0.000 >= min_delta = 5e-05. New best score: 0.000
Epoch 11, global step 264: 'val_MSE_loss' reached 0.00021 (best 0.00021), saving model to 'results/MAE/Task-4B_SuperRes_finetuned_super_res/ckpts/epoch=11 | val_MSE_loss=0.000.ckpt' as top 1
Epoch 12, global step 286: 'val_MSE_loss' reached 0.00018 (best 0.00018), saving model to 'results/MAE/Task-4B_SuperRes_finetuned_super_res/ckpts/epoch=12 | val_MSE_loss=0.000.ckpt' as top 1
Epoch 13, global step 308: 'val_MSE_loss' was not in top 1
Epoch 14, global step 330: 'val_MSE_loss' was not in top 1
Epoch 15, global step 352: 'val_MSE_loss' was not in top 1
Epoch 16, global step 374: 'val_MSE_loss' was not in top 1
Epoch 17, global step 396: 'val_MSE_loss' reached 0.00017 (best 0.00017), saving model to 'results/MAE/Task-4B_SuperRes_finetuned_super_res/ckpts/epoch=17 | val_MSE_loss=0.000.ckpt' as top 1
Epoch 18, global step 418: 'val_MSE_loss' was not in top 1
[rank: 0] Monitored metric val_MSE_loss did not improve in the last 8 records. Best score: 0.000. Signaling Trainer to stop.
[rank: 1] Monitored metric val_MSE_loss did not improve in the last 8 records. Best score: 0.000. Signaling Trainer to stop.
Epoch 19, global step 440: 'val_MSE_loss' was not in top 1
Epoch 19/199 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 64/64 0:00:23 ‚Ä¢ 0:00:00 2.83it/s v_num: ud_7      
                                                               val_MSE_loss:    
                                                               0.000 val_PSNR:  
                                                               37.718 val_SSIM: 
                                                               0.957            
                                                               train_MSE_loss:  
                                                               0.000 train_PSNR:
                                                               38.092           
                                                               train_SSIM: 0.957
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
SLURM auto-requeueing enabled. Setting signal handlers.
SLURM auto-requeueing enabled. Setting signal handlers.
/home/s_porwal_me.iitr/miniconda3/envs/deeplense/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:232: Using `DistributedSampler` with the dataloaders. During `trainer.test()`, it is recommended to use `Trainer(devices=1, num_nodes=1)` to ensure each sample/batch gets evaluated exactly once. Otherwise, multi-device settings use `DistributedSampler` that replicates some samples to make sure all devices have same batch size in case of uneven inputs.
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ        Test metric        ‚îÉ       DataLoader 0        ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ       test_MSE_loss       ‚îÇ  0.00016903816140256822   ‚îÇ
‚îÇ         test_PSNR         ‚îÇ     37.7221794128418      ‚îÇ
‚îÇ         test_SSIM         ‚îÇ    0.9573417901992798     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Testing ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 0:00:01 ‚Ä¢ 0:00:00 7.03it/s 
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mTask-4B_SuperRes_finetuned_super_res[0m at: [34mhttps://wandb.ai/shri_krishna/DeepLense_FoundationModels_Analysis/runs/ibqziwud[0m
